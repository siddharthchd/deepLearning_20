{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashionMNIST_DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1vSMvVeCXhIkj3H5/6nin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddharthchd/deepLearning_20/blob/main/GANs/fashionMNIST_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBlb9uhEA5ti"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3h9yYL7B85J"
      },
      "source": [
        "batch_size = 64\n",
        "images = np.concatenate([x_train, x_test])\n",
        "images = images / 255.\n",
        "images = np.reshape(images, (-1, 28, 28, 1))\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "dataset = dataset.shuffle(buffer_size = 1024).batch(batch_size).prefetch(32)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g6tv_DVB_TO",
        "outputId": "8215e0f7-caf7-404d-dd13-4d8cc16be410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bQ1T4wsCAsH"
      },
      "source": [
        "def discriminator():\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      \n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 5, strides= 2, padding = 'same', input_shape = (28, 28, 1)),\n",
        "      #tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.LeakyReLU(0.3),\n",
        "      tf.keras.layers.Dropout(0.3),           \n",
        "\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 5, strides= 2, padding = 'same'),\n",
        "      #tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.LeakyReLU(0.3),\n",
        "      tf.keras.layers.Dropout(0.3), \n",
        "\n",
        "      tf.keras.layers.GlobalMaxPooling2D(),\n",
        "      #tf.keras.layers.Flatten(),\n",
        "      #tf.keras.layers.Dense(512),\n",
        "      #tf.keras.layers.LeakyReLU(0.3),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qye8sEG4NZH6",
        "outputId": "31ad2c02-2dab-4ec6-f52e-b1f515db42f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "discriminator = discriminator()\n",
        "discriminator.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 206,721\n",
            "Trainable params: 206,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5llohVzUiQa"
      },
      "source": [
        "def generator(gauss_size):\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(7 * 7 * 256, input_dim = gauss_size),\n",
        "      tf.keras.layers.Reshape((7, 7, 256)),\n",
        "      \n",
        "      tf.keras.layers.Conv2DTranspose(256, 5, padding = 'same'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "      tf.keras.layers.Conv2DTranspose(128, 5, strides = 1, padding = 'same'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "      tf.keras.layers.Conv2DTranspose(64, 5, strides = 2, padding = 'same'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "      tf.keras.layers.Conv2DTranspose(1, 2, strides = 2, activation = 'tanh')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edeA2xtPXIHJ",
        "outputId": "004bd109-5603-4735-8d5c-ad92de63fa65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "generator = generator(100)\n",
        "generator.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_43 (Dense)             (None, 12544)             1266944   \n",
            "_________________________________________________________________\n",
            "reshape_28 (Reshape)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_76 (Conv2DT (None, 7, 7, 256)         1638656   \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_96 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_77 (Conv2DT (None, 7, 7, 128)         819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_97 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_78 (Conv2DT (None, 14, 14, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_98 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_79 (Conv2DT (None, 28, 28, 1)         257       \n",
            "=================================================================\n",
            "Total params: 3,931,841\n",
            "Trainable params: 3,930,945\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ROL2F44ZK_H"
      },
      "source": [
        "class GAN(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, discriminator, generator, latent_dim):\n",
        "\n",
        "    super(GAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def compile(self, discriminator_opt, generator_opt, loss):\n",
        "\n",
        "    super(GAN, self).compile()\n",
        "    self.discriminator_opt = discriminator_opt\n",
        "    self.generator_opt = generator_opt\n",
        "    self.loss = loss\n",
        "\n",
        "  def train_step(self, images):\n",
        "\n",
        "    images = images[0]\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    random_vecs = tf.random.normal(shape = (batch_size, self.latent_dim))\n",
        "\n",
        "    generated_images = self.generator(random_vecs)\n",
        "    combined_images=  tf.concat([generated_images, images], axis = 0)\n",
        "\n",
        "    labels = tf.conact([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis = 0)\n",
        "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      predictions = self.discriminator_opt(combined_images)\n",
        "      discriminator_loss = self.loss(labels, predicitions)\n",
        "\n",
        "    gradients = tape.gradient(discriminator_loss, self.discriminator.trainable_weights)\n",
        "    self.discriminator_opt.apply_gradients(zip(gradients, self.discriminator.trainable_weights))\n",
        "\n",
        "    radom_vecs = tf.random.normal(shape = (batch_size, self.latent_dim))\n",
        "\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      predictions = self.discriminator(self.generator(random_vecs))\n",
        "      generator_loss = self.loss(misleading_labels, predictions)\n",
        "      gradients = tape.gradient(generator_loss, self.generator.trainable_weights)\n",
        "      self.generator_opt.apply_gradients(zip(gradients, self.generator.trainable_weights))\n",
        "\n",
        "      return {'discriminator_loss' : discriminator_loss, 'generator_loss' : generator_loss}"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5o9ACrVfcaQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}