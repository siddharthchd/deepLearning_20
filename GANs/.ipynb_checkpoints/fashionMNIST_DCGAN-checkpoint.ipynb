{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/siddharthchd/deepLearning_20/blob/main/GANs/fashionMNIST_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lBlb9uhEA5ti"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q3h9yYL7B85J"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "images = np.concatenate([x_train, x_test])\n",
    "images = images / 255.\n",
    "images = np.reshape(images, (-1, 28, 28, 1))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "dataset = dataset.shuffle(buffer_size = 1024).batch(batch_size).prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4g6tv_DVB_TO",
    "outputId": "8215e0f7-caf7-404d-dd13-4d8cc16be410"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3bQ1T4wsCAsH"
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "\n",
    "  model = tf.keras.Sequential([\n",
    "      \n",
    "      tf.keras.layers.Conv2D(64, kernel_size = 5, strides= 2, padding = 'same', input_shape = (28, 28, 1)),\n",
    "      #tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.LeakyReLU(0.3),\n",
    "      tf.keras.layers.Dropout(0.3),           \n",
    "\n",
    "      tf.keras.layers.Conv2D(128, kernel_size = 5, strides= 2, padding = 'same'),\n",
    "      #tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.LeakyReLU(0.3),\n",
    "      tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "      tf.keras.layers.GlobalMaxPooling2D(),\n",
    "      #tf.keras.layers.Flatten(),\n",
    "      #tf.keras.layers.Dense(512),\n",
    "      #tf.keras.layers.LeakyReLU(0.3),\n",
    "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qye8sEG4NZH6",
    "outputId": "31ad2c02-2dab-4ec6-f52e-b1f515db42f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 206,721\n",
      "Trainable params: 206,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "d5llohVzUiQa"
   },
   "outputs": [],
   "source": [
    "def generator(gauss_size):\n",
    "\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(7 * 7 * 256, input_dim = gauss_size),\n",
    "      tf.keras.layers.Reshape((7, 7, 256)),\n",
    "      \n",
    "      tf.keras.layers.Conv2DTranspose(256, 5, padding = 'same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.3),\n",
    "\n",
    "      tf.keras.layers.Conv2DTranspose(128, 5, strides = 1, padding = 'same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.3),\n",
    "\n",
    "      tf.keras.layers.Conv2DTranspose(64, 5, strides = 2, padding = 'same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.3),\n",
    "\n",
    "      tf.keras.layers.Conv2DTranspose(1, 2, strides = 2, activation = 'tanh')\n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edeA2xtPXIHJ",
    "outputId": "004bd109-5603-4735-8d5c-ad92de63fa65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "reshape_28 (Reshape)         (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_76 (Conv2DT (None, 7, 7, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_96 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_77 (Conv2DT (None, 7, 7, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_97 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_78 (Conv2DT (None, 14, 14, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_98 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_79 (Conv2DT (None, 28, 28, 1)         257       \n",
      "=================================================================\n",
      "Total params: 3,931,841\n",
      "Trainable params: 3,930,945\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator(100)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "-ROL2F44ZK_H"
   },
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, discriminator, generator, latent_dim):\n",
    "\n",
    "    super(GAN, self).__init__()\n",
    "    self.discriminator = discriminator\n",
    "    self.generator = generator\n",
    "    self.latent_dim = latent_dim\n",
    "\n",
    "  def compile(self, discriminator_opt, generator_opt, loss):\n",
    "\n",
    "    super(GAN, self).compile()\n",
    "    self.discriminator_opt = discriminator_opt\n",
    "    self.generator_opt = generator_opt\n",
    "    self.loss = loss\n",
    "\n",
    "  def train_step(self, images):\n",
    "\n",
    "    images = images[0]\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    random_vecs = tf.random.normal(shape = (batch_size, self.latent_dim))\n",
    "\n",
    "    generated_images = self.generator(random_vecs)\n",
    "    combined_images=  tf.concat([generated_images, images], axis = 0)\n",
    "\n",
    "    labels = tf.conact([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis = 0)\n",
    "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "      predictions = self.discriminator_opt(combined_images)\n",
    "      discriminator_loss = self.loss(labels, predicitions)\n",
    "\n",
    "    gradients = tape.gradient(discriminator_loss, self.discriminator.trainable_weights)\n",
    "    self.discriminator_opt.apply_gradients(zip(gradients, self.discriminator.trainable_weights))\n",
    "\n",
    "    radom_vecs = tf.random.normal(shape = (batch_size, self.latent_dim))\n",
    "\n",
    "    misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "      predictions = self.discriminator(self.generator(random_vecs))\n",
    "      generator_loss = self.loss(misleading_labels, predictions)\n",
    "      gradients = tape.gradient(generator_loss, self.generator.trainable_weights)\n",
    "      self.generator_opt.apply_gradients(zip(gradients, self.generator.trainable_weights))\n",
    "\n",
    "      return {'discriminator_loss' : discriminator_loss, 'generator_loss' : generator_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5o9ACrVfcaQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1vSMvVeCXhIkj3H5/6nin",
   "include_colab_link": true,
   "name": "fashionMNIST_DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
